
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "examples/40_advanced/example_get_pipeline_components.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        Click :ref:`here <sphx_glr_download_examples_40_advanced_example_get_pipeline_components.py>`
        to download the full example code or to run this example in your browser via Binder

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_examples_40_advanced_example_get_pipeline_components.py:


======================
Obtain run information
======================

The following example shows how to obtain information from a finished
Auto-sklearn run. In particular, it shows:
* how to query which models were evaluated by Auto-sklearn
* how to query the models in the final ensemble
* how to get general statistics on the what Auto-sklearn evaluated

Auto-sklearn is a wrapper on top of
the sklearn models. This example illustrates how to interact
with the sklearn components directly, in this case a PCA preprocessor.

.. GENERATED FROM PYTHON SOURCE LINES 17-25

.. code-block:: default

    from pprint import pprint

    import sklearn.datasets
    import sklearn.metrics

    import autosklearn.classification









.. GENERATED FROM PYTHON SOURCE LINES 26-28

Data Loading
============

.. GENERATED FROM PYTHON SOURCE LINES 28-34

.. code-block:: default


    X, y = sklearn.datasets.load_breast_cancer(return_X_y=True)
    X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(
        X, y, random_state=1
    )








.. GENERATED FROM PYTHON SOURCE LINES 35-37

Build and fit the classifier
============================

.. GENERATED FROM PYTHON SOURCE LINES 37-48

.. code-block:: default


    automl = autosklearn.classification.AutoSklearnClassifier(
        time_left_for_this_task=30,
        per_run_time_limit=10,
        disable_evaluator_output=False,
        # To simplify querying the models in the final ensemble, we
        # restrict auto-sklearn to use only pca as a preprocessor
        include={"feature_preprocessor": ["pca"]},
    )
    automl.fit(X_train, y_train, dataset_name="breast_cancer")





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Fitting to the training data:   0%|          | 0/30 [00:00<?, ?it/s, The total time budget for this task is 0:00:30]    Fitting to the training data:   3%|3         | 1/30 [00:01<00:29,  1.00s/it, The total time budget for this task is 0:00:30]    Fitting to the training data:   7%|6         | 2/30 [00:02<00:28,  1.00s/it, The total time budget for this task is 0:00:30]    Fitting to the training data:  10%|#         | 3/30 [00:03<00:27,  1.00s/it, The total time budget for this task is 0:00:30]    Fitting to the training data:  13%|#3        | 4/30 [00:04<00:26,  1.00s/it, The total time budget for this task is 0:00:30]    Fitting to the training data:  17%|#6        | 5/30 [00:05<00:25,  1.00s/it, The total time budget for this task is 0:00:30]    Fitting to the training data:  20%|##        | 6/30 [00:06<00:24,  1.00s/it, The total time budget for this task is 0:00:30]    Fitting to the training data:  23%|##3       | 7/30 [00:07<00:23,  1.00s/it, The total time budget for this task is 0:00:30]    Fitting to the training data:  27%|##6       | 8/30 [00:08<00:22,  1.01s/it, The total time budget for this task is 0:00:30]    Fitting to the training data:  30%|###       | 9/30 [00:09<00:21,  1.01s/it, The total time budget for this task is 0:00:30]    Fitting to the training data:  33%|###3      | 10/30 [00:10<00:20,  1.01s/it, The total time budget for this task is 0:00:30]    Fitting to the training data:  37%|###6      | 11/30 [00:11<00:19,  1.01s/it, The total time budget for this task is 0:00:30]    Fitting to the training data:  40%|####      | 12/30 [00:12<00:18,  1.01s/it, The total time budget for this task is 0:00:30]    Fitting to the training data:  43%|####3     | 13/30 [00:13<00:17,  1.01s/it, The total time budget for this task is 0:00:30]    Fitting to the training data:  47%|####6     | 14/30 [00:14<00:16,  1.00s/it, The total time budget for this task is 0:00:30]    Fitting to the training data:  50%|#####     | 15/30 [00:15<00:15,  1.01s/it, The total time budget for this task is 0:00:30]    Fitting to the training data:  53%|#####3    | 16/30 [00:16<00:14,  1.01s/it, The total time budget for this task is 0:00:30]    Fitting to the training data:  57%|#####6    | 17/30 [00:17<00:13,  1.01s/it, The total time budget for this task is 0:00:30]    Fitting to the training data:  60%|######    | 18/30 [00:18<00:12,  1.00s/it, The total time budget for this task is 0:00:30]    Fitting to the training data:  63%|######3   | 19/30 [00:19<00:11,  1.01s/it, The total time budget for this task is 0:00:30]    Fitting to the training data:  67%|######6   | 20/30 [00:20<00:10,  1.01s/it, The total time budget for this task is 0:00:30]    Fitting to the training data:  70%|#######   | 21/30 [00:21<00:09,  1.02s/it, The total time budget for this task is 0:00:30]    Fitting to the training data:  73%|#######3  | 22/30 [00:22<00:08,  1.01s/it, The total time budget for this task is 0:00:30]    Fitting to the training data: 100%|##########| 30/30 [00:22<00:00,  1.35it/s, The total time budget for this task is 0:00:30]

    AutoSklearnClassifier(ensemble_class=<class 'autosklearn.ensembles.ensemble_selection.EnsembleSelection'>,
                          include={'feature_preprocessor': ['pca']},
                          per_run_time_limit=10, time_left_for_this_task=30)



.. GENERATED FROM PYTHON SOURCE LINES 49-51

Predict using the model
=======================

.. GENERATED FROM PYTHON SOURCE LINES 51-56

.. code-block:: default


    predictions = automl.predict(X_test)
    print("Accuracy score:{}".format(sklearn.metrics.accuracy_score(y_test, predictions)))






.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Accuracy score:0.951048951048951




.. GENERATED FROM PYTHON SOURCE LINES 57-73

Report the models found by Auto-Sklearn
=======================================

Auto-sklearn uses
`Ensemble Selection <https://www.cs.cornell.edu/~alexn/papers/shotgun.icml04.revised.rev2.pdf>`_
to construct ensembles in a post-hoc fashion. The ensemble is a linear
weighting of all models constructed during the hyperparameter optimization.
This prints the final ensemble. It is a dictionary where ``model_id`` of
each model is a key, and value is a dictionary containing information
of that model. A model's dict contains its ``'model_id'``, ``'rank'``,
``'cost'``, ``'ensemble_weight'``, and the model itself. The model is
given by the ``'data_preprocessor'``, ``'feature_preprocessor'``,
``'regressor'/'classifier'`` and ``'sklearn_regressor'/'sklearn_classifier'``
entries. But for the ``'cv'`` resampling strategy, the same for each cv
model is stored in the ``'estimators'`` list in the dict, along with the
``'voting_model'``.

.. GENERATED FROM PYTHON SOURCE LINES 73-76

.. code-block:: default


    pprint(automl.show_models(), indent=4)





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    {   2: {   'balancing': Balancing(random_state=1),
               'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice object at 0x7f2cef33ca30>,
               'cost': 0.07801418439716312,
               'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice object at 0x7f2cf857fc10>,
               'ensemble_weight': 0.16,
               'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice object at 0x7f2cef33c880>,
               'model_id': 2,
               'rank': 4,
               'sklearn_classifier': RandomForestClassifier(max_features=5, n_estimators=512, n_jobs=1,
                           random_state=1, warm_start=True)},
        3: {   'balancing': Balancing(random_state=1),
               'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice object at 0x7f2cf70feee0>,
               'cost': 0.07092198581560283,
               'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice object at 0x7f2cf45d3fa0>,
               'ensemble_weight': 0.06,
               'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice object at 0x7f2ceeeea430>,
               'model_id': 3,
               'rank': 3,
               'sklearn_classifier': RandomForestClassifier(max_features=1, min_samples_leaf=2, min_samples_split=20,
                           n_estimators=512, n_jobs=1, random_state=1,
                           warm_start=True)},
        4: {   'balancing': Balancing(random_state=1, strategy='weighting'),
               'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice object at 0x7f2cefea08b0>,
               'cost': 0.028368794326241176,
               'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice object at 0x7f2cf45d3790>,
               'ensemble_weight': 0.24,
               'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice object at 0x7f2cf84eebb0>,
               'model_id': 4,
               'rank': 1,
               'sklearn_classifier': MLPClassifier(activation='tanh', alpha=1.103855734598575e-05, beta_1=0.999,
                  beta_2=0.9, early_stopping=True,
                  hidden_layer_sizes=(229, 229, 229),
                  learning_rate_init=0.00014375616988222174, max_iter=32,
                  n_iter_no_change=32, random_state=1, verbose=0, warm_start=True)},
        5: {   'balancing': Balancing(random_state=1, strategy='weighting'),
               'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice object at 0x7f2cf61a3340>,
               'cost': 0.1063829787234043,
               'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice object at 0x7f2cecb91910>,
               'ensemble_weight': 0.06,
               'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice object at 0x7f2cf61a3f70>,
               'model_id': 5,
               'rank': 7,
               'sklearn_classifier': KNeighborsClassifier(n_neighbors=4, weights='distance')},
        6: {   'balancing': Balancing(random_state=1),
               'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice object at 0x7f2cefe4a220>,
               'cost': 0.11347517730496459,
               'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice object at 0x7f2cefac28b0>,
               'ensemble_weight': 0.14,
               'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice object at 0x7f2cefe4a6a0>,
               'model_id': 6,
               'rank': 9,
               'sklearn_classifier': SVC(C=100.5905006626969, cache_size=1811.609375, coef0=0.08087614244138486,
        gamma=0.011333066835975528, kernel='poly', max_iter=-1.0, random_state=1,
        tol=0.012391313886912093)},
        7: {   'balancing': Balancing(random_state=1, strategy='weighting'),
               'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice object at 0x7f2cecbebc40>,
               'cost': 0.1063829787234043,
               'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice object at 0x7f2ceff30b20>,
               'ensemble_weight': 0.08,
               'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice object at 0x7f2cef359280>,
               'model_id': 7,
               'rank': 8,
               'sklearn_classifier': LinearSVC(C=10.369811497206404, class_weight='balanced', dual=False,
              intercept_scaling=1.0, random_state=1, tol=0.0015130257264171173)},
        8: {   'balancing': Balancing(random_state=1),
               'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice object at 0x7f2cf50f8550>,
               'cost': 0.028368794326241176,
               'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice object at 0x7f2cf48d99d0>,
               'ensemble_weight': 0.1,
               'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice object at 0x7f2cf50f8cd0>,
               'model_id': 8,
               'rank': 2,
               'sklearn_classifier': KNeighborsClassifier(n_neighbors=10, p=1)},
        9: {   'balancing': Balancing(random_state=1, strategy='weighting'),
               'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice object at 0x7f2cf79ab3a0>,
               'cost': 0.08510638297872342,
               'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice object at 0x7f2cf5043af0>,
               'ensemble_weight': 0.08,
               'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice object at 0x7f2cf79abf40>,
               'model_id': 9,
               'rank': 6,
               'sklearn_classifier': DecisionTreeClassifier(class_weight='balanced', criterion='entropy',
                           max_depth=1, min_samples_leaf=12, min_samples_split=13,
                           random_state=1)},
        10: {   'balancing': Balancing(random_state=1),
                'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice object at 0x7f2ced7363a0>,
                'cost': 0.07801418439716312,
                'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice object at 0x7f2cecbebb50>,
                'ensemble_weight': 0.08,
                'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice object at 0x7f2ced736c70>,
                'model_id': 10,
                'rank': 5,
                'sklearn_classifier': HistGradientBoostingClassifier(early_stopping=False,
                                   l2_regularization=3.511604744219034e-05,
                                   learning_rate=0.06666502293259023, max_iter=512,
                                   max_leaf_nodes=18, min_samples_leaf=5,
                                   n_iter_no_change=0, random_state=1,
                                   validation_fraction=None, warm_start=True)}}




.. GENERATED FROM PYTHON SOURCE LINES 77-82

Report statistics about the search
==================================

Print statistics about the auto-sklearn run such as number of
iterations, number of models failed with a time out etc.

.. GENERATED FROM PYTHON SOURCE LINES 82-84

.. code-block:: default

    print(automl.sprint_statistics())





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    auto-sklearn results:
      Dataset name: breast_cancer
      Metric: accuracy
      Best validation score: 0.971631
      Number of target algorithm runs: 9
      Number of successful target algorithm runs: 9
      Number of crashed target algorithm runs: 0
      Number of target algorithms that exceeded the time limit: 0
      Number of target algorithms that exceeded the memory limit: 0





.. GENERATED FROM PYTHON SOURCE LINES 85-91

Detailed statistics about the search - part 1
=============================================

Auto-sklearn also keeps detailed statistics of the hyperparameter
optimization procedurce, which are stored in a so-called
`run history <https://automl.github.io/SMAC3/main/api/smac.runhistory.runhistory.html#smac.runhistory.runhistory.RunHistory>`_.

.. GENERATED FROM PYTHON SOURCE LINES 91-94

.. code-block:: default


    print(automl.automl_.runhistory_)





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    <smac.runhistory.runhistory.RunHistory object at 0x7f2cf74dbf40>




.. GENERATED FROM PYTHON SOURCE LINES 95-96

Runs are stored inside an ``OrderedDict`` called ``data``:

.. GENERATED FROM PYTHON SOURCE LINES 96-99

.. code-block:: default


    print(len(automl.automl_.runhistory_.data))





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    10




.. GENERATED FROM PYTHON SOURCE LINES 100-101

Let's iterative over all entries

.. GENERATED FROM PYTHON SOURCE LINES 101-107

.. code-block:: default


    for run_key in automl.automl_.runhistory_.data:
        print("#########")
        print(run_key)
        print(automl.automl_.runhistory_.data[run_key])





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    #########
    RunKey(config_id=1, instance_id='{"task_id": "breast_cancer"}', seed=0, budget=0.0)
    RunValue(cost=0.07801418439716312, time=1.798516035079956, status=<StatusType.SUCCESS: 1>, starttime=1670994006.3789434, endtime=1670994008.2071998, additional_info={'duration': 1.6923842430114746, 'num_run': 2, 'train_loss': 0.0, 'configuration_origin': 'Initial design'})
    #########
    RunKey(config_id=2, instance_id='{"task_id": "breast_cancer"}', seed=0, budget=0.0)
    RunValue(cost=0.07092198581560283, time=1.527057409286499, status=<StatusType.SUCCESS: 1>, starttime=1670994008.2716963, endtime=1670994009.8237057, additional_info={'duration': 1.4262714385986328, 'num_run': 3, 'train_loss': 0.06315789473684208, 'configuration_origin': 'Initial design'})
    #########
    RunKey(config_id=3, instance_id='{"task_id": "breast_cancer"}', seed=0, budget=0.0)
    RunValue(cost=0.028368794326241176, time=1.3078303337097168, status=<StatusType.SUCCESS: 1>, starttime=1670994009.927415, endtime=1670994011.262809, additional_info={'duration': 1.2299919128417969, 'num_run': 4, 'train_loss': 0.04210526315789476, 'configuration_origin': 'Initial design'})
    #########
    RunKey(config_id=4, instance_id='{"task_id": "breast_cancer"}', seed=0, budget=0.0)
    RunValue(cost=0.1063829787234043, time=0.7644035816192627, status=<StatusType.SUCCESS: 1>, starttime=1670994011.3842885, endtime=1670994012.173979, additional_info={'duration': 0.6879367828369141, 'num_run': 5, 'train_loss': 0.0, 'configuration_origin': 'Initial design'})
    #########
    RunKey(config_id=5, instance_id='{"task_id": "breast_cancer"}', seed=0, budget=0.0)
    RunValue(cost=0.11347517730496459, time=0.6236791610717773, status=<StatusType.SUCCESS: 1>, starttime=1670994012.3045688, endtime=1670994012.950633, additional_info={'duration': 0.5528998374938965, 'num_run': 6, 'train_loss': 0.09122807017543855, 'configuration_origin': 'Initial design'})
    #########
    RunKey(config_id=6, instance_id='{"task_id": "breast_cancer"}', seed=0, budget=0.0)
    RunValue(cost=0.1063829787234043, time=0.7856378555297852, status=<StatusType.SUCCESS: 1>, starttime=1670994015.0531447, endtime=1670994015.8609006, additional_info={'duration': 0.7022364139556885, 'num_run': 7, 'train_loss': 0.1473684210526316, 'configuration_origin': 'Random Search (sorted)'})
    #########
    RunKey(config_id=7, instance_id='{"task_id": "breast_cancer"}', seed=0, budget=0.0)
    RunValue(cost=0.028368794326241176, time=0.7651448249816895, status=<StatusType.SUCCESS: 1>, starttime=1670994018.0186417, endtime=1670994018.8070369, additional_info={'duration': 0.68475341796875, 'num_run': 8, 'train_loss': 0.03157894736842104, 'configuration_origin': 'Random Search (sorted)'})
    #########
    RunKey(config_id=8, instance_id='{"task_id": "breast_cancer"}', seed=0, budget=0.0)
    RunValue(cost=0.08510638297872342, time=0.7804615497589111, status=<StatusType.SUCCESS: 1>, starttime=1670994019.003122, endtime=1670994019.8063557, additional_info={'duration': 0.7055728435516357, 'num_run': 9, 'train_loss': 0.07017543859649122, 'configuration_origin': 'Random Search'})
    #########
    RunKey(config_id=9, instance_id='{"task_id": "breast_cancer"}', seed=0, budget=0.0)
    RunValue(cost=0.07801418439716312, time=1.3950037956237793, status=<StatusType.SUCCESS: 1>, starttime=1670994022.345984, endtime=1670994023.7671824, additional_info={'duration': 1.312840461730957, 'num_run': 10, 'train_loss': 0.0, 'configuration_origin': 'Random Search (sorted)'})
    #########
    RunKey(config_id=10, instance_id='{"task_id": "breast_cancer"}', seed=0, budget=0.0)
    RunValue(cost=1.0, time=0.0, status=<StatusType.STOP: 8>, starttime=1670994026.4573576, endtime=1670994026.457358, additional_info={})




.. GENERATED FROM PYTHON SOURCE LINES 108-109

and have a detailed look at one entry:

.. GENERATED FROM PYTHON SOURCE LINES 109-113

.. code-block:: default


    run_key = list(automl.automl_.runhistory_.data.keys())[0]
    run_value = automl.automl_.runhistory_.data[run_key]








.. GENERATED FROM PYTHON SOURCE LINES 114-115

The ``run_key`` contains all information describing a run:

.. GENERATED FROM PYTHON SOURCE LINES 115-121

.. code-block:: default


    print("Configuration ID:", run_key.config_id)
    print("Instance:", run_key.instance_id)
    print("Seed:", run_key.seed)
    print("Budget:", run_key.budget)





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Configuration ID: 1
    Instance: {"task_id": "breast_cancer"}
    Seed: 0
    Budget: 0.0




.. GENERATED FROM PYTHON SOURCE LINES 122-123

and the configuration can be looked up in the run history as well:

.. GENERATED FROM PYTHON SOURCE LINES 123-126

.. code-block:: default


    print(automl.automl_.runhistory_.ids_config[run_key.config_id])





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Configuration(values={
      'balancing:strategy': 'none',
      'classifier:__choice__': 'random_forest',
      'classifier:random_forest:bootstrap': 'True',
      'classifier:random_forest:criterion': 'gini',
      'classifier:random_forest:max_depth': 'None',
      'classifier:random_forest:max_features': 0.5,
      'classifier:random_forest:max_leaf_nodes': 'None',
      'classifier:random_forest:min_impurity_decrease': 0.0,
      'classifier:random_forest:min_samples_leaf': 1,
      'classifier:random_forest:min_samples_split': 2,
      'classifier:random_forest:min_weight_fraction_leaf': 0.0,
      'data_preprocessor:__choice__': 'feature_type',
      'data_preprocessor:feature_type:numerical_transformer:imputation:strategy': 'mean',
      'data_preprocessor:feature_type:numerical_transformer:rescaling:__choice__': 'standardize',
      'feature_preprocessor:__choice__': 'pca',
      'feature_preprocessor:pca:keep_variance': 0.9999,
      'feature_preprocessor:pca:whiten': 'False',
    })





.. GENERATED FROM PYTHON SOURCE LINES 127-133

The only other important entry is the budget in case you are using
auto-sklearn with
:ref:`sphx_glr_examples_60_search_example_successive_halving.py`.
The remaining parts of the key can be ignored for auto-sklearn and are
only there because the underlying optimizer, SMAC, can handle more general
problems, too.

.. GENERATED FROM PYTHON SOURCE LINES 135-136

The ``run_value`` contains all output from running the configuration:

.. GENERATED FROM PYTHON SOURCE LINES 136-144

.. code-block:: default


    print("Cost:", run_value.cost)
    print("Time:", run_value.time)
    print("Status:", run_value.status)
    print("Additional information:", run_value.additional_info)
    print("Start time:", run_value.starttime)
    print("End time", run_value.endtime)





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Cost: 0.07801418439716312
    Time: 1.798516035079956
    Status: StatusType.SUCCESS
    Additional information: {'duration': 1.6923842430114746, 'num_run': 2, 'train_loss': 0.0, 'configuration_origin': 'Initial design'}
    Start time: 1670994006.3789434
    End time 1670994008.2071998




.. GENERATED FROM PYTHON SOURCE LINES 145-151

Cost is basically the same as a loss. In case the metric to optimize for
should be maximized, it is internally transformed into a minimization
metric. Additionally, the status type gives information on whether the run
was successful, while the additional information's most interesting entry
is the internal training loss. Furthermore, there is detailed information
on the runtime available.

.. GENERATED FROM PYTHON SOURCE LINES 153-156

As an example, let's find the best configuration evaluated. As
Auto-sklearn solves a minimization problem internally, we need to look
for the entry with the lowest loss:

.. GENERATED FROM PYTHON SOURCE LINES 156-168

.. code-block:: default


    losses_and_configurations = [
        (run_value.cost, run_key.config_id)
        for run_key, run_value in automl.automl_.runhistory_.data.items()
    ]
    losses_and_configurations.sort()
    print("Lowest loss:", losses_and_configurations[0][0])
    print(
        "Best configuration:",
        automl.automl_.runhistory_.ids_config[losses_and_configurations[0][1]],
    )





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Lowest loss: 0.028368794326241176
    Best configuration: Configuration(values={
      'balancing:strategy': 'weighting',
      'classifier:__choice__': 'mlp',
      'classifier:mlp:activation': 'tanh',
      'classifier:mlp:alpha': 1.103855734598575e-05,
      'classifier:mlp:batch_size': 'auto',
      'classifier:mlp:beta_1': 0.9,
      'classifier:mlp:beta_2': 0.999,
      'classifier:mlp:early_stopping': 'valid',
      'classifier:mlp:epsilon': 1e-08,
      'classifier:mlp:hidden_layer_depth': 3,
      'classifier:mlp:learning_rate_init': 0.00014375616988222174,
      'classifier:mlp:n_iter_no_change': 32,
      'classifier:mlp:num_nodes_per_layer': 229,
      'classifier:mlp:shuffle': 'True',
      'classifier:mlp:solver': 'adam',
      'classifier:mlp:tol': 0.0001,
      'classifier:mlp:validation_fraction': 0.1,
      'data_preprocessor:__choice__': 'feature_type',
      'data_preprocessor:feature_type:numerical_transformer:imputation:strategy': 'most_frequent',
      'data_preprocessor:feature_type:numerical_transformer:rescaling:__choice__': 'quantile_transformer',
      'data_preprocessor:feature_type:numerical_transformer:rescaling:quantile_transformer:n_quantiles': 180,
      'data_preprocessor:feature_type:numerical_transformer:rescaling:quantile_transformer:output_distribution': 'uniform',
      'feature_preprocessor:__choice__': 'pca',
      'feature_preprocessor:pca:keep_variance': 0.7895711479212801,
      'feature_preprocessor:pca:whiten': 'True',
    })





.. GENERATED FROM PYTHON SOURCE LINES 169-176

Detailed statistics about the search - part 2
=============================================

To maintain compatibility with scikit-learn, Auto-sklearn gives the
same data as
`cv_results_ <https://scikit-learn.org/stable/modules/generated/sklearn.
model_selection.GridSearchCV.html>`_.

.. GENERATED FROM PYTHON SOURCE LINES 176-179

.. code-block:: default


    print(automl.cv_results_)





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    {'model_ids': [2, 3, 4, 5, 6, 7, 8, 9, 10], 'mean_test_score': array([0.92198582, 0.92907801, 0.97163121, 0.89361702, 0.88652482,
           0.89361702, 0.97163121, 0.91489362, 0.92198582]), 'rank_test_scores': array([4, 3, 1, 7, 9, 7, 1, 6, 4]), 'mean_fit_time': array([1.79851604, 1.52705741, 1.30783033, 0.76440358, 0.62367916,
           0.78563786, 0.76514482, 0.78046155, 1.3950038 ]), 'params': [{'balancing:strategy': 'none', 'classifier:__choice__': 'random_forest', 'data_preprocessor:__choice__': 'feature_type', 'feature_preprocessor:__choice__': 'pca', 'classifier:random_forest:bootstrap': 'True', 'classifier:random_forest:criterion': 'gini', 'classifier:random_forest:max_depth': 'None', 'classifier:random_forest:max_features': 0.5, 'classifier:random_forest:max_leaf_nodes': 'None', 'classifier:random_forest:min_impurity_decrease': 0.0, 'classifier:random_forest:min_samples_leaf': 1, 'classifier:random_forest:min_samples_split': 2, 'classifier:random_forest:min_weight_fraction_leaf': 0.0, 'data_preprocessor:feature_type:numerical_transformer:imputation:strategy': 'mean', 'data_preprocessor:feature_type:numerical_transformer:rescaling:__choice__': 'standardize', 'feature_preprocessor:pca:keep_variance': 0.9999, 'feature_preprocessor:pca:whiten': 'False'}, {'balancing:strategy': 'none', 'classifier:__choice__': 'random_forest', 'data_preprocessor:__choice__': 'feature_type', 'feature_preprocessor:__choice__': 'pca', 'classifier:random_forest:bootstrap': 'True', 'classifier:random_forest:criterion': 'gini', 'classifier:random_forest:max_depth': 'None', 'classifier:random_forest:max_features': 0.9331254454871041, 'classifier:random_forest:max_leaf_nodes': 'None', 'classifier:random_forest:min_impurity_decrease': 0.0, 'classifier:random_forest:min_samples_leaf': 2, 'classifier:random_forest:min_samples_split': 20, 'classifier:random_forest:min_weight_fraction_leaf': 0.0, 'data_preprocessor:feature_type:numerical_transformer:imputation:strategy': 'mean', 'data_preprocessor:feature_type:numerical_transformer:rescaling:__choice__': 'none', 'feature_preprocessor:pca:keep_variance': 0.9967857433838874, 'feature_preprocessor:pca:whiten': 'False'}, {'balancing:strategy': 'weighting', 'classifier:__choice__': 'mlp', 'data_preprocessor:__choice__': 'feature_type', 'feature_preprocessor:__choice__': 'pca', 'classifier:mlp:activation': 'tanh', 'classifier:mlp:alpha': 1.103855734598575e-05, 'classifier:mlp:batch_size': 'auto', 'classifier:mlp:beta_1': 0.9, 'classifier:mlp:beta_2': 0.999, 'classifier:mlp:early_stopping': 'valid', 'classifier:mlp:epsilon': 1e-08, 'classifier:mlp:hidden_layer_depth': 3, 'classifier:mlp:learning_rate_init': 0.00014375616988222174, 'classifier:mlp:n_iter_no_change': 32, 'classifier:mlp:num_nodes_per_layer': 229, 'classifier:mlp:shuffle': 'True', 'classifier:mlp:solver': 'adam', 'classifier:mlp:tol': 0.0001, 'data_preprocessor:feature_type:numerical_transformer:imputation:strategy': 'most_frequent', 'data_preprocessor:feature_type:numerical_transformer:rescaling:__choice__': 'quantile_transformer', 'feature_preprocessor:pca:keep_variance': 0.7895711479212801, 'feature_preprocessor:pca:whiten': 'True', 'classifier:mlp:validation_fraction': 0.1, 'data_preprocessor:feature_type:numerical_transformer:rescaling:quantile_transformer:n_quantiles': 180, 'data_preprocessor:feature_type:numerical_transformer:rescaling:quantile_transformer:output_distribution': 'uniform'}, {'balancing:strategy': 'weighting', 'classifier:__choice__': 'k_nearest_neighbors', 'data_preprocessor:__choice__': 'feature_type', 'feature_preprocessor:__choice__': 'pca', 'classifier:k_nearest_neighbors:n_neighbors': 4, 'classifier:k_nearest_neighbors:p': 2, 'classifier:k_nearest_neighbors:weights': 'distance', 'data_preprocessor:feature_type:numerical_transformer:imputation:strategy': 'mean', 'data_preprocessor:feature_type:numerical_transformer:rescaling:__choice__': 'normalize', 'feature_preprocessor:pca:keep_variance': 0.8047274080856589, 'feature_preprocessor:pca:whiten': 'False'}, {'balancing:strategy': 'none', 'classifier:__choice__': 'libsvm_svc', 'data_preprocessor:__choice__': 'feature_type', 'feature_preprocessor:__choice__': 'pca', 'classifier:libsvm_svc:C': 100.5905006626969, 'classifier:libsvm_svc:gamma': 0.011333066835975528, 'classifier:libsvm_svc:kernel': 'poly', 'classifier:libsvm_svc:max_iter': -1, 'classifier:libsvm_svc:shrinking': 'True', 'classifier:libsvm_svc:tol': 0.012391313886912093, 'data_preprocessor:feature_type:numerical_transformer:imputation:strategy': 'mean', 'data_preprocessor:feature_type:numerical_transformer:rescaling:__choice__': 'minmax', 'feature_preprocessor:pca:keep_variance': 0.9290439925152777, 'feature_preprocessor:pca:whiten': 'False', 'classifier:libsvm_svc:coef0': 0.08087614244138486, 'classifier:libsvm_svc:degree': 3}, {'balancing:strategy': 'weighting', 'classifier:__choice__': 'liblinear_svc', 'data_preprocessor:__choice__': 'feature_type', 'feature_preprocessor:__choice__': 'pca', 'classifier:liblinear_svc:C': 10.369811497206404, 'classifier:liblinear_svc:dual': 'False', 'classifier:liblinear_svc:fit_intercept': 'True', 'classifier:liblinear_svc:intercept_scaling': 1, 'classifier:liblinear_svc:loss': 'squared_hinge', 'classifier:liblinear_svc:multi_class': 'ovr', 'classifier:liblinear_svc:penalty': 'l2', 'classifier:liblinear_svc:tol': 0.0015130257264171173, 'data_preprocessor:feature_type:numerical_transformer:imputation:strategy': 'median', 'data_preprocessor:feature_type:numerical_transformer:rescaling:__choice__': 'robust_scaler', 'feature_preprocessor:pca:keep_variance': 0.5306607720040878, 'feature_preprocessor:pca:whiten': 'False', 'data_preprocessor:feature_type:numerical_transformer:rescaling:robust_scaler:q_max': 0.9866104280704078, 'data_preprocessor:feature_type:numerical_transformer:rescaling:robust_scaler:q_min': 0.20576464288464985}, {'balancing:strategy': 'none', 'classifier:__choice__': 'k_nearest_neighbors', 'data_preprocessor:__choice__': 'feature_type', 'feature_preprocessor:__choice__': 'pca', 'classifier:k_nearest_neighbors:n_neighbors': 10, 'classifier:k_nearest_neighbors:p': 1, 'classifier:k_nearest_neighbors:weights': 'uniform', 'data_preprocessor:feature_type:numerical_transformer:imputation:strategy': 'median', 'data_preprocessor:feature_type:numerical_transformer:rescaling:__choice__': 'quantile_transformer', 'feature_preprocessor:pca:keep_variance': 0.9923006586696794, 'feature_preprocessor:pca:whiten': 'False', 'data_preprocessor:feature_type:numerical_transformer:rescaling:quantile_transformer:n_quantiles': 1866, 'data_preprocessor:feature_type:numerical_transformer:rescaling:quantile_transformer:output_distribution': 'normal'}, {'balancing:strategy': 'weighting', 'classifier:__choice__': 'decision_tree', 'data_preprocessor:__choice__': 'feature_type', 'feature_preprocessor:__choice__': 'pca', 'classifier:decision_tree:criterion': 'entropy', 'classifier:decision_tree:max_depth_factor': 0.07400222370559417, 'classifier:decision_tree:max_features': 1.0, 'classifier:decision_tree:max_leaf_nodes': 'None', 'classifier:decision_tree:min_impurity_decrease': 0.0, 'classifier:decision_tree:min_samples_leaf': 12, 'classifier:decision_tree:min_samples_split': 13, 'classifier:decision_tree:min_weight_fraction_leaf': 0.0, 'data_preprocessor:feature_type:numerical_transformer:imputation:strategy': 'most_frequent', 'data_preprocessor:feature_type:numerical_transformer:rescaling:__choice__': 'standardize', 'feature_preprocessor:pca:keep_variance': 0.9710934401815425, 'feature_preprocessor:pca:whiten': 'True'}, {'balancing:strategy': 'none', 'classifier:__choice__': 'gradient_boosting', 'data_preprocessor:__choice__': 'feature_type', 'feature_preprocessor:__choice__': 'pca', 'classifier:gradient_boosting:early_stop': 'off', 'classifier:gradient_boosting:l2_regularization': 3.511604744219034e-05, 'classifier:gradient_boosting:learning_rate': 0.06666502293259023, 'classifier:gradient_boosting:loss': 'auto', 'classifier:gradient_boosting:max_bins': 255, 'classifier:gradient_boosting:max_depth': 'None', 'classifier:gradient_boosting:max_leaf_nodes': 18, 'classifier:gradient_boosting:min_samples_leaf': 5, 'classifier:gradient_boosting:scoring': 'loss', 'classifier:gradient_boosting:tol': 1e-07, 'data_preprocessor:feature_type:numerical_transformer:imputation:strategy': 'mean', 'data_preprocessor:feature_type:numerical_transformer:rescaling:__choice__': 'none', 'feature_preprocessor:pca:keep_variance': 0.9968418627262279, 'feature_preprocessor:pca:whiten': 'True'}], 'status': ['Success', 'Success', 'Success', 'Success', 'Success', 'Success', 'Success', 'Success', 'Success'], 'budgets': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'param_balancing:strategy': masked_array(data=['none', 'none', 'weighting', 'weighting', 'none',
                       'weighting', 'none', 'weighting', 'none'],
                 mask=[False, False, False, False, False, False, False, False,
                       False],
           fill_value='N/A',
                dtype='<U9'), 'param_classifier:__choice__': masked_array(data=['random_forest', 'random_forest', 'mlp',
                       'k_nearest_neighbors', 'libsvm_svc', 'liblinear_svc',
                       'k_nearest_neighbors', 'decision_tree',
                       'gradient_boosting'],
                 mask=[False, False, False, False, False, False, False, False,
                       False],
           fill_value='N/A',
                dtype='<U19'), 'param_data_preprocessor:__choice__': masked_array(data=['feature_type', 'feature_type', 'feature_type',
                       'feature_type', 'feature_type', 'feature_type',
                       'feature_type', 'feature_type', 'feature_type'],
                 mask=[False, False, False, False, False, False, False, False,
                       False],
           fill_value='N/A',
                dtype='<U12'), 'param_feature_preprocessor:__choice__': masked_array(data=['pca', 'pca', 'pca', 'pca', 'pca', 'pca', 'pca', 'pca',
                       'pca'],
                 mask=[False, False, False, False, False, False, False, False,
                       False],
           fill_value='N/A',
                dtype='<U3'), 'param_classifier:adaboost:algorithm': masked_array(data=[--, --, --, --, --, --, --, --, --],
                 mask=[ True,  True,  True,  True,  True,  True,  True,  True,
                        True],
           fill_value=1e+20,
                dtype=float64), 'param_classifier:adaboost:learning_rate': masked_array(data=[--, --, --, --, --, --, --, --, --],
                 mask=[ True,  True,  True,  True,  True,  True,  True,  True,
                        True],
           fill_value=1e+20,
                dtype=float64), 'param_classifier:adaboost:max_depth': masked_array(data=[--, --, --, --, --, --, --, --, --],
                 mask=[ True,  True,  True,  True,  True,  True,  True,  True,
                        True],
           fill_value=1e+20,
                dtype=float64), 'param_classifier:adaboost:n_estimators': masked_array(data=[--, --, --, --, --, --, --, --, --],
                 mask=[ True,  True,  True,  True,  True,  True,  True,  True,
                        True],
           fill_value=1e+20,
                dtype=float64), 'param_classifier:bernoulli_nb:alpha': masked_array(data=[--, --, --, --, --, --, --, --, --],
                 mask=[ True,  True,  True,  True,  True,  True,  True,  True,
                        True],
           fill_value=1e+20,
                dtype=float64), 'param_classifier:bernoulli_nb:fit_prior': masked_array(data=[--, --, --, --, --, --, --, --, --],
                 mask=[ True,  True,  True,  True,  True,  True,  True,  True,
                        True],
           fill_value=1e+20,
                dtype=float64), 'param_classifier:decision_tree:criterion': masked_array(data=[--, --, --, --, --, --, --, 'entropy', --],
                 mask=[ True,  True,  True,  True,  True,  True,  True, False,
                        True],
           fill_value='N/A',
                dtype='<U32'), 'param_classifier:decision_tree:max_depth_factor': masked_array(data=[--, --, --, --, --, --, --, 0.07400222370559417, --],
                 mask=[ True,  True,  True,  True,  True,  True,  True, False,
                        True],
           fill_value=1e+20), 'param_classifier:decision_tree:max_features': masked_array(data=[--, --, --, --, --, --, --, 1.0, --],
                 mask=[ True,  True,  True,  True,  True,  True,  True, False,
                        True],
           fill_value=1e+20), 'param_classifier:decision_tree:max_leaf_nodes': masked_array(data=[--, --, --, --, --, --, --, 'None', --],
                 mask=[ True,  True,  True,  True,  True,  True,  True, False,
                        True],
           fill_value='N/A',
                dtype='<U32'), 'param_classifier:decision_tree:min_impurity_decrease': masked_array(data=[--, --, --, --, --, --, --, 0.0, --],
                 mask=[ True,  True,  True,  True,  True,  True,  True, False,
                        True],
           fill_value=1e+20), 'param_classifier:decision_tree:min_samples_leaf': masked_array(data=[--, --, --, --, --, --, --, 12.0, --],
                 mask=[ True,  True,  True,  True,  True,  True,  True, False,
                        True],
           fill_value=1e+20), 'param_classifier:decision_tree:min_samples_split': masked_array(data=[--, --, --, --, --, --, --, 13.0, --],
                 mask=[ True,  True,  True,  True,  True,  True,  True, False,
                        True],
           fill_value=1e+20), 'param_classifier:decision_tree:min_weight_fraction_leaf': masked_array(data=[--, --, --, --, --, --, --, 0.0, --],
                 mask=[ True,  True,  True,  True,  True,  True,  True, False,
                        True],
           fill_value=1e+20), 'param_classifier:extra_trees:bootstrap': masked_array(data=[--, --, --, --, --, --, --, --, --],
                 mask=[ True,  True,  True,  True,  True,  True,  True,  True,
                        True],
           fill_value=1e+20,
                dtype=float64), 'param_classifier:extra_trees:criterion': masked_array(data=[--, --, --, --, --, --, --, --, --],
                 mask=[ True,  True,  True,  True,  True,  True,  True,  True,
                        True],
           fill_value=1e+20,
                dtype=float64), 'param_classifier:extra_trees:max_depth': masked_array(data=[--, --, --, --, --, --, --, --, --],
                 mask=[ True,  True,  True,  True,  True,  True,  True,  True,
                        True],
           fill_value=1e+20,
                dtype=float64), 'param_classifier:extra_trees:max_features': masked_array(data=[--, --, --, --, --, --, --, --, --],
                 mask=[ True,  True,  True,  True,  True,  True,  True,  True,
                        True],
           fill_value=1e+20,
                dtype=float64), 'param_classifier:extra_trees:max_leaf_nodes': masked_array(data=[--, --, --, --, --, --, --, --, --],
                 mask=[ True,  True,  True,  True,  True,  True,  True,  True,
                        True],
           fill_value=1e+20,
                dtype=float64), 'param_classifier:extra_trees:min_impurity_decrease': masked_array(data=[--, --, --, --, --, --, --, --, --],
                 mask=[ True,  True,  True,  True,  True,  True,  True,  True,
                        True],
           fill_value=1e+20,
                dtype=float64), 'param_classifier:extra_trees:min_samples_leaf': masked_array(data=[--, --, --, --, --, --, --, --, --],
                 mask=[ True,  True,  True,  True,  True,  True,  True,  True,
                        True],
           fill_value=1e+20,
                dtype=float64), 'param_classifier:extra_trees:min_samples_split': masked_array(data=[--, --, --, --, --, --, --, --, --],
                 mask=[ True,  True,  True,  True,  True,  True,  True,  True,
                        True],
           fill_value=1e+20,
                dtype=float64), 'param_classifier:extra_trees:min_weight_fraction_leaf': masked_array(data=[--, --, --, --, --, --, --, --, --],
                 mask=[ True,  True,  True,  True,  True,  True,  True,  True,
                        True],
           fill_value=1e+20,
                dtype=float64), 'param_classifier:gradient_boosting:early_stop': masked_array(data=[--, --, --, --, --, --, --, --, 'off'],
                 mask=[ True,  True,  True,  True,  True,  True,  True,  True,
                       False],
           fill_value='N/A',
                dtype='<U32'), 'param_classifier:gradient_boosting:l2_regularization': masked_array(data=[--, --, --, --, --, --, --, --, 3.511604744219034e-05],
                 mask=[ True,  True,  True,  True,  True,  True,  True,  True,
                       False],
           fill_value=1e+20), 'param_classifier:gradient_boosting:learning_rate': masked_array(data=[--, --, --, --, --, --, --, --, 0.06666502293259023],
                 mask=[ True,  True,  True,  True,  True,  True,  True,  True,
                       False],
           fill_value=1e+20), 'param_classifier:gradient_boosting:loss': masked_array(data=[--, --, --, --, --, --, --, --, 'auto'],
                 mask=[ True,  True,  True,  True,  True,  True,  True,  True,
                       False],
           fill_value='N/A',
                dtype='<U32'), 'param_classifier:gradient_boosting:max_bins': masked_array(data=[--, --, --, --, --, --, --, --, 255.0],
                 mask=[ True,  True,  True,  True,  True,  True,  True,  True,
                       False],
           fill_value=1e+20), 'param_classifier:gradient_boosting:max_depth': masked_array(data=[--, --, --, --, --, --, --, --, 'None'],
                 mask=[ True,  True,  True,  True,  True,  True,  True,  True,
                       False],
           fill_value='N/A',
                dtype='<U32'), 'param_classifier:gradient_boosting:max_leaf_nodes': masked_array(data=[--, --, --, --, --, --, --, --, 18.0],
                 mask=[ True,  True,  True,  True,  True,  True,  True,  True,
                       False],
           fill_value=1e+20), 'param_classifier:gradient_boosting:min_samples_leaf': masked_array(data=[--, --, --, --, --, --, --, --, 5.0],
                 mask=[ True,  True,  True,  True,  True,  True,  True,  True,
                       False],
           fill_value=1e+20), 'param_classifier:gradient_boosting:scoring': masked_array(data=[--, --, --, --, --, --, --, --, 'loss'],
                 mask=[ True,  True,  True,  True,  True,  True,  True,  True,
                       False],
           fill_value='N/A',
                dtype='<U32'), 'param_classifier:gradient_boosting:tol': masked_array(data=[--, --, --, --, --, --, --, --, 1e-07],
                 mask=[ True,  True,  True,  True,  True,  True,  True,  True,
                       False],
           fill_value=1e+20), 'param_classifier:k_nearest_neighbors:n_neighbors': masked_array(data=[--, --, --, 4.0, --, --, 10.0, --, --],
                 mask=[ True,  True,  True, False,  True,  True, False,  True,
                        True],
           fill_value=1e+20), 'param_classifier:k_nearest_neighbors:p': masked_array(data=[--, --, --, 2.0, --, --, 1.0, --, --],
                 mask=[ True,  True,  True, False,  True,  True, False,  True,
                        True],
           fill_value=1e+20), 'param_classifier:k_nearest_neighbors:weights': masked_array(data=[--, --, --, 'distance', --, --, 'uniform', --, --],
                 mask=[ True,  True,  True, False,  True,  True, False,  True,
                        True],
           fill_value='N/A',
                dtype='<U32'), 'param_classifier:lda:shrinkage': masked_array(data=[--, --, --, --, --, --, --, --, --],
                 mask=[ True,  True,  True,  True,  True,  True,  True,  True,
                        True],
           fill_value=1e+20,
                dtype=float64), 'param_classifier:lda:tol': masked_array(data=[--, --, --, --, --, --, --, --, --],
                 mask=[ True,  True,  True,  True,  True,  True,  True,  True,
                        True],
           fill_value=1e+20,
                dtype=float64), 'param_classifier:liblinear_svc:C': masked_array(data=[--, --, --, --, --, 10.369811497206404, --, --, --],
                 mask=[ True,  True,  True,  True,  True, False,  True,  True,
                        True],
           fill_value=1e+20), 'param_classifier:liblinear_svc:dual': masked_array(data=[--, --, --, --, --, 'False', --, --, --],
                 mask=[ True,  True,  True,  True,  True, False,  True,  True,
                        True],
           fill_value='N/A',
                dtype='<U32'), 'param_classifier:liblinear_svc:fit_intercept': masked_array(data=[--, --, --, --, --, 'True', --, --, --],
                 mask=[ True,  True,  True,  True,  True, False,  True,  True,
                        True],
           fill_value='N/A',
                dtype='<U32'), 'param_classifier:liblinear_svc:intercept_scaling': masked_array(data=[--, --, --, --, --, 1.0, --, --, --],
                 mask=[ True,  True,  True,  True,  True, False,  True,  True,
                        True],
           fill_value=1e+20), 'param_classifier:liblinear_svc:loss': masked_array(data=[--, --, --, --, --, 'squared_hinge', --, --, --],
                 mask=[ True,  True,  True,  True,  True, False,  True,  True,
                        True],
           fill_value='N/A',
                dtype='<U32'), 'param_classifier:liblinear_svc:multi_class': masked_array(data=[--, --, --, --, --, 'ovr', --, --, --],
                 mask=[ True,  True,  True,  True,  True, False,  True,  True,
                        True],
           fill_value='N/A',
                dtype='<U32'), 'param_classifier:liblinear_svc:penalty': masked_array(data=[--, --, --, --, --, 'l2', --, --, --],
                 mask=[ True,  True,  True,  True,  True, False,  True,  True,
                        True],
           fill_value='N/A',
                dtype='<U32'), 'param_classifier:liblinear_svc:tol': masked_array(data=[--, --, --, --, --, 0.0015130257264171173, --, --, --],
                 mask=[ True,  True,  True,  True,  True, False,  True,  True,
                        True],
           fill_value=1e+20), 'param_classifier:libsvm_svc:C': masked_array(data=[--, --, --, --, 100.5905006626969, --, --, --, --],
                 mask=[ True,  True,  True,  True, False,  True,  True,  True,
                        True],
           fill_value=1e+20), 'param_classifier:libsvm_svc:gamma': masked_array(data=[--, --, --, --, 0.011333066835975528, --, --, --, --],
                 mask=[ True,  True,  True,  True, False,  True,  True,  True,
                        True],
           fill_value=1e+20), 'param_classifier:libsvm_svc:kernel': masked_array(data=[--, --, --, --, 'poly', --, --, --, --],
                 mask=[ True,  True,  True,  True, False,  True,  True,  True,
                        True],
           fill_value='N/A',
                dtype='<U32'), 'param_classifier:libsvm_svc:max_iter': masked_array(data=[--, --, --, --, -1.0, --, --, --, --],
                 mask=[ True,  True,  True,  True, False,  True,  True,  True,
                        True],
           fill_value=1e+20), 'param_classifier:libsvm_svc:shrinking': masked_array(data=[--, --, --, --, 'True', --, --, --, --],
                 mask=[ True,  True,  True,  True, False,  True,  True,  True,
                        True],
           fill_value='N/A',
                dtype='<U32'), 'param_classifier:libsvm_svc:tol': masked_array(data=[--, --, --, --, 0.012391313886912093, --, --, --, --],
                 mask=[ True,  True,  True,  True, False,  True,  True,  True,
                        True],
           fill_value=1e+20), 'param_classifier:mlp:activation': masked_array(data=[--, --, 'tanh', --, --, --, --, --, --],
                 mask=[ True,  True, False,  True,  True,  True,  True,  True,
                        True],
           fill_value='N/A',
                dtype='<U32'), 'param_classifier:mlp:alpha': masked_array(data=[--, --, 1.103855734598575e-05, --, --, --, --, --, --],
                 mask=[ True,  True, False,  True,  True,  True,  True,  True,
                        True],
           fill_value=1e+20), 'param_classifier:mlp:batch_size': masked_array(data=[--, --, 'auto', --, --, --, --, --, --],
                 mask=[ True,  True, False,  True,  True,  True,  True,  True,
                        True],
           fill_value='N/A',
                dtype='<U32'), 'param_classifier:mlp:beta_1': masked_array(data=[--, --, 0.9, --, --, --, --, --, --],
                 mask=[ True,  True, False,  True,  True,  True,  True,  True,
                        True],
           fill_value=1e+20), 'param_classifier:mlp:beta_2': masked_array(data=[--, --, 0.999, --, --, --, --, --, --],
                 mask=[ True,  True, False,  True,  True,  True,  True,  True,
                        True],
           fill_value=1e+20), 'param_classifier:mlp:early_stopping': masked_array(data=[--, --, 'valid', --, --, --, --, --, --],
                 mask=[ True,  True, False,  True,  True,  True,  True,  True,
                        True],
           fill_value='N/A',
                dtype='<U32'), 'param_classifier:mlp:epsilon': masked_array(data=[--, --, 1e-08, --, --, --, --, --, --],
                 mask=[ True,  True, False,  True,  True,  True,  True,  True,
                        True],
           fill_value=1e+20), 'param_classifier:mlp:hidden_layer_depth': masked_array(data=[--, --, 3.0, --, --, --, --, --, --],
                 mask=[ True,  True, False,  True,  True,  True,  True,  True,
                        True],
           fill_value=1e+20), 'param_classifier:mlp:learning_rate_init': masked_array(data=[--, --, 0.00014375616988222174, --, --, --, --, --, --],
                 mask=[ True,  True, False,  True,  True,  True,  True,  True,
                        True],
           fill_value=1e+20), 'param_classifier:mlp:n_iter_no_change': masked_array(data=[--, --, 32.0, --, --, --, --, --, --],
                 mask=[ True,  True, False,  True,  True,  True,  True,  True,
                        True],
           fill_value=1e+20), 'param_classifier:mlp:num_nodes_per_layer': masked_array(data=[--, --, 229.0, --, --, --, --, --, --],
                 mask=[ True,  True, False,  True,  True,  True,  True,  True,
                        True],
           fill_value=1e+20), 'param_classifier:mlp:shuffle': masked_array(data=[--, --, 'True', --, --, --, --, --, --],
                 mask=[ True,  True, False,  True,  True,  True,  True,  True,
                        True],
           fill_value='N/A',
                dtype='<U32'), 'param_classifier:mlp:solver': masked_array(data=[--, --, 'adam', --, --, --, --, --, --],
                 mask=[ True,  True, False,  True,  True,  True,  True,  True,
                        True],
           fill_value='N/A',
                dtype='<U32'), 'param_classifier:mlp:tol': masked_array(data=[--, --, 0.0001, --, --, --, --, --, --],
                 mask=[ True,  True, False,  True,  True,  True,  True,  True,
                        True],
           fill_value=1e+20), 'param_classifier:passive_aggressive:C': masked_array(data=[--, --, --, --, --, --, --, --, --],
                 mask=[ True,  True,  True,  True,  True,  True,  True,  True,
                        True],
           fill_value=1e+20,
                dtype=float64), 'param_classifier:passive_aggressive:average': masked_array(data=[--, --, --, --, --, --, --, --, --],
                 mask=[ True,  True,  True,  True,  True,  True,  True,  True,
                        True],
           fill_value=1e+20,
                dtype=float64), 'param_classifier:passive_aggressive:fit_intercept': masked_array(data=[--, --, --, --, --, --, --, --, --],
                 mask=[ True,  True,  True,  True,  True,  True,  True,  True,
                        True],
           fill_value=1e+20,
                dtype=float64), 'param_classifier:passive_aggressive:loss': masked_array(data=[--, --, --, --, --, --, --, --, --],
                 mask=[ True,  True,  True,  True,  True,  True,  True,  True,
                        True],
           fill_value=1e+20,
                dtype=float64), 'param_classifier:passive_aggressive:tol': masked_array(data=[--, --, --, --, --, --, --, --, --],
                 mask=[ True,  True,  True,  True,  True,  True,  True,  True,
                        True],
           fill_value=1e+20,
                dtype=float64), 'param_classifier:qda:reg_param': masked_array(data=[--, --, --, --, --, --, --, --, --],
                 mask=[ True,  True,  True,  True,  True,  True,  True,  True,
                        True],
           fill_value=1e+20,
                dtype=float64), 'param_classifier:random_forest:bootstrap': masked_array(data=['True', 'True', --, --, --, --, --, --, --],
                 mask=[False, False,  True,  True,  True,  True,  True,  True,
                        True],
           fill_value='N/A',
                dtype='<U32'), 'param_classifier:random_forest:criterion': masked_array(data=['gini', 'gini', --, --, --, --, --, --, --],
                 mask=[False, False,  True,  True,  True,  True,  True,  True,
                        True],
           fill_value='N/A',
                dtype='<U32'), 'param_classifier:random_forest:max_depth': masked_array(data=['None', 'None', --, --, --, --, --, --, --],
                 mask=[False, False,  True,  True,  True,  True,  True,  True,
                        True],
           fill_value='N/A',
                dtype='<U32'), 'param_classifier:random_forest:max_features': masked_array(data=[0.5, 0.9331254454871041, --, --, --, --, --, --, --],
                 mask=[False, False,  True,  True,  True,  True,  True,  True,
                        True],
           fill_value=1e+20), 'param_classifier:random_forest:max_leaf_nodes': masked_array(data=['None', 'None', --, --, --, --, --, --, --],
                 mask=[False, False,  True,  True,  True,  True,  True,  True,
                        True],
           fill_value='N/A',
                dtype='<U32'), 'param_classifier:random_forest:min_impurity_decrease': masked_array(data=[0.0, 0.0, --, --, --, --, --, --, --],
                 mask=[False, False,  True,  True,  True,  True,  True,  True,
                        True],
           fill_value=1e+20), 'param_classifier:random_forest:min_samples_leaf': masked_array(data=[1.0, 2.0, --, --, --, --, --, --, --],
                 mask=[False, False,  True,  True,  True,  True,  True,  True,
                        True],
           fill_value=1e+20), 'param_classifier:random_forest:min_samples_split': masked_array(data=[2.0, 20.0, --, --, --, --, --, --, --],
                 mask=[False, False,  True,  True,  True,  True,  True,  True,
                        True],
           fill_value=1e+20), 'param_classifier:random_forest:min_weight_fraction_leaf': masked_array(data=[0.0, 0.0, --, --, --, --, --, --, --],
                 mask=[False, False,  True,  True,  True,  True,  True,  True,
                        True],
           fill_value=1e+20), 'param_classifier:sgd:alpha': masked_array(data=[--, --, --, --, --, --, --, --, --],
                 mask=[ True,  True,  True,  True,  True,  True,  True,  True,
                        True],
           fill_value=1e+20,
                dtype=float64), 'param_classifier:sgd:average': masked_array(data=[--, --, --, --, --, --, --, --, --],
                 mask=[ True,  True,  True,  True,  True,  True,  True,  True,
                        True],
           fill_value=1e+20,
                dtype=float64), 'param_classifier:sgd:fit_intercept': masked_array(data=[--, --, --, --, --, --, --, --, --],
                 mask=[ True,  True,  True,  True,  True,  True,  True,  True,
                        True],
           fill_value=1e+20,
                dtype=float64), 'param_classifier:sgd:learning_rate': masked_array(data=[--, --, --, --, --, --, --, --, --],
                 mask=[ True,  True,  True,  True,  True,  True,  True,  True,
                        True],
           fill_value=1e+20,
                dtype=float64), 'param_classifier:sgd:loss': masked_array(data=[--, --, --, --, --, --, --, --, --],
                 mask=[ True,  True,  True,  True,  True,  True,  True,  True,
                        True],
           fill_value=1e+20,
                dtype=float64), 'param_classifier:sgd:penalty': masked_array(data=[--, --, --, --, --, --, --, --, --],
                 mask=[ True,  True,  True,  True,  True,  True,  True,  True,
                        True],
           fill_value=1e+20,
                dtype=float64), 'param_classifier:sgd:tol': masked_array(data=[--, --, --, --, --, --, --, --, --],
                 mask=[ True,  True,  True,  True,  True,  True,  True,  True,
                        True],
           fill_value=1e+20,
                dtype=float64), 'param_data_preprocessor:feature_type:numerical_transformer:imputation:strategy': masked_array(data=['mean', 'mean', 'most_frequent', 'mean', 'mean',
                       'median', 'median', 'most_frequent', 'mean'],
                 mask=[False, False, False, False, False, False, False, False,
                       False],
           fill_value='N/A',
                dtype='<U13'), 'param_data_preprocessor:feature_type:numerical_transformer:rescaling:__choice__': masked_array(data=['standardize', 'none', 'quantile_transformer',
                       'normalize', 'minmax', 'robust_scaler',
                       'quantile_transformer', 'standardize', 'none'],
                 mask=[False, False, False, False, False, False, False, False,
                       False],
           fill_value='N/A',
                dtype='<U20'), 'param_feature_preprocessor:pca:keep_variance': masked_array(data=[0.9999, 0.9967857433838874, 0.7895711479212801,
                       0.8047274080856589, 0.9290439925152777,
                       0.5306607720040878, 0.9923006586696794,
                       0.9710934401815425, 0.9968418627262279],
                 mask=[False, False, False, False, False, False, False, False,
                       False],
           fill_value=1e+20), 'param_feature_preprocessor:pca:whiten': masked_array(data=['False', 'False', 'True', 'False', 'False', 'False',
                       'False', 'True', 'True'],
                 mask=[False, False, False, False, False, False, False, False,
                       False],
           fill_value='N/A',
                dtype='<U5'), 'param_classifier:gradient_boosting:n_iter_no_change': masked_array(data=[--, --, --, --, --, --, --, --, --],
                 mask=[ True,  True,  True,  True,  True,  True,  True,  True,
                        True],
           fill_value=1e+20,
                dtype=float64), 'param_classifier:gradient_boosting:validation_fraction': masked_array(data=[--, --, --, --, --, --, --, --, --],
                 mask=[ True,  True,  True,  True,  True,  True,  True,  True,
                        True],
           fill_value=1e+20,
                dtype=float64), 'param_classifier:lda:shrinkage_factor': masked_array(data=[--, --, --, --, --, --, --, --, --],
                 mask=[ True,  True,  True,  True,  True,  True,  True,  True,
                        True],
           fill_value=1e+20,
                dtype=float64), 'param_classifier:libsvm_svc:coef0': masked_array(data=[--, --, --, --, 0.08087614244138486, --, --, --, --],
                 mask=[ True,  True,  True,  True, False,  True,  True,  True,
                        True],
           fill_value=1e+20), 'param_classifier:libsvm_svc:degree': masked_array(data=[--, --, --, --, 3.0, --, --, --, --],
                 mask=[ True,  True,  True,  True, False,  True,  True,  True,
                        True],
           fill_value=1e+20), 'param_classifier:mlp:validation_fraction': masked_array(data=[--, --, 0.1, --, --, --, --, --, --],
                 mask=[ True,  True, False,  True,  True,  True,  True,  True,
                        True],
           fill_value=1e+20), 'param_classifier:sgd:epsilon': masked_array(data=[--, --, --, --, --, --, --, --, --],
                 mask=[ True,  True,  True,  True,  True,  True,  True,  True,
                        True],
           fill_value=1e+20,
                dtype=float64), 'param_classifier:sgd:eta0': masked_array(data=[--, --, --, --, --, --, --, --, --],
                 mask=[ True,  True,  True,  True,  True,  True,  True,  True,
                        True],
           fill_value=1e+20,
                dtype=float64), 'param_classifier:sgd:l1_ratio': masked_array(data=[--, --, --, --, --, --, --, --, --],
                 mask=[ True,  True,  True,  True,  True,  True,  True,  True,
                        True],
           fill_value=1e+20,
                dtype=float64), 'param_classifier:sgd:power_t': masked_array(data=[--, --, --, --, --, --, --, --, --],
                 mask=[ True,  True,  True,  True,  True,  True,  True,  True,
                        True],
           fill_value=1e+20,
                dtype=float64), 'param_data_preprocessor:feature_type:numerical_transformer:rescaling:quantile_transformer:n_quantiles': masked_array(data=[--, --, 180.0, --, --, --, 1866.0, --, --],
                 mask=[ True,  True, False,  True,  True,  True, False,  True,
                        True],
           fill_value=1e+20), 'param_data_preprocessor:feature_type:numerical_transformer:rescaling:quantile_transformer:output_distribution': masked_array(data=[--, --, 'uniform', --, --, --, 'normal', --, --],
                 mask=[ True,  True, False,  True,  True,  True, False,  True,
                        True],
           fill_value='N/A',
                dtype='<U32'), 'param_data_preprocessor:feature_type:numerical_transformer:rescaling:robust_scaler:q_max': masked_array(data=[--, --, --, --, --, 0.9866104280704078, --, --, --],
                 mask=[ True,  True,  True,  True,  True, False,  True,  True,
                        True],
           fill_value=1e+20), 'param_data_preprocessor:feature_type:numerical_transformer:rescaling:robust_scaler:q_min': masked_array(data=[--, --, --, --, --, 0.20576464288464985, --, --, --],
                 mask=[ True,  True,  True,  True,  True, False,  True,  True,
                        True],
           fill_value=1e+20)}




.. GENERATED FROM PYTHON SOURCE LINES 180-185

Inspect the components of the best model
========================================

Iterate over the components of the model and print
The explained variance ratio per stage

.. GENERATED FROM PYTHON SOURCE LINES 185-198

.. code-block:: default

    for i, (weight, pipeline) in enumerate(automl.get_models_with_weights()):
        for stage_name, component in pipeline.named_steps.items():
            if "feature_preprocessor" in stage_name:
                print(
                    "The {}th pipeline has a explained variance of {}".format(
                        i,
                        # The component is an instance of AutoSklearnChoice.
                        # Access the sklearn object via the choice attribute
                        # We want the explained variance attributed of
                        # each principal component
                        component.choice.preprocessor.explained_variance_ratio_,
                    )
                )




.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    The 0th pipeline has a explained variance of [0.45954164 0.18010277 0.09814953 0.06334655]
    The 1th pipeline has a explained variance of [4.32956881e-01 1.79057296e-01 1.11737571e-01 6.80724345e-02
     5.94611519e-02 3.70629898e-02 2.38430977e-02 1.49326086e-02
     1.37641366e-02 1.13704890e-02 1.03737258e-02 8.74116751e-03
     7.57629717e-03 4.86528503e-03 3.32225143e-03 2.55773043e-03
     2.20759805e-03 1.88675402e-03 1.36245140e-03 1.03409213e-03
     8.39749085e-04 7.91287172e-04 6.75655689e-04 5.42961621e-04
     5.02641737e-04 2.07827509e-04 1.74597367e-04]
    The 2th pipeline has a explained variance of [0.49503611 0.16649281 0.09111888 0.07213284 0.04865917 0.03208923
     0.01851537 0.01223987]
    The 3th pipeline has a explained variance of [0.46038401 0.16124884 0.09747816 0.06923404 0.06142479 0.03312917
     0.03182802 0.01555463 0.01348582 0.00965531 0.00870982 0.007397
     0.00547082 0.00443245 0.00396559 0.00313575 0.0022883  0.00195796
     0.00156348]
    The 4th pipeline has a explained variance of [0.72985767]
    The 5th pipeline has a explained variance of [0.43295688 0.1790573  0.11173757 0.06807243 0.05946115 0.03706299
     0.0238431  0.01493261 0.01376414 0.01137049 0.01037373 0.00874117]
    The 6th pipeline has a explained variance of [0.98080571 0.01684553]
    The 7th pipeline has a explained variance of [0.98080571 0.01684553]
    The 8th pipeline has a explained variance of [0.76699224 0.17152095]





.. rst-class:: sphx-glr-timing

   **Total running time of the script:** ( 0 minutes  27.638 seconds)


.. _sphx_glr_download_examples_40_advanced_example_get_pipeline_components.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example


    .. container:: binder-badge

      .. image:: images/binder_badge_logo.svg
        :target: https://mybinder.org/v2/gh/automl/auto-sklearn/development?urlpath=lab/tree/notebooks/examples/40_advanced/example_get_pipeline_components.ipynb
        :alt: Launch binder
        :width: 150 px

    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: example_get_pipeline_components.py <example_get_pipeline_components.py>`

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: example_get_pipeline_components.ipynb <example_get_pipeline_components.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
